# Projeto: ClassificaÃ§Ã£o de GÃªnero LiterÃ¡rio com LLM + RAG

Este projeto implementa um sistema de classificaÃ§Ã£o de gÃªnero literÃ¡rio
utilizando **LLMs (Large Language Models)** em formato **GGUF**,
combinadas com **RAG (Retrieval-Augmented Generation)** para aumento de
precisÃ£o, eficiÃªncia e interpretabilidade.

## ğŸš€ VisÃ£o Geral

O sistema utiliza:

-   **Qwen2.5-1.5B-Instruct-GGUF** para classificaÃ§Ã£o textual;
-   **Sentence-BERT (all-MiniLM-L6-v2)** para geraÃ§Ã£o de embeddings;
-   **FAISS** para busca vetorial eficiente;
-   **Pipeline RAG** para recuperaÃ§Ã£o de exemplos relevantes antes da
    inferÃªncia;
-   **Dataset prÃ³prio** construÃ­do a partir de textos do *Project
    Gutenberg* (DomÃ­nio PÃºblico).

## ğŸ“‚ Estrutura Geral

    â”œâ”€â”€ gutenberg_texts/              # Textos brutos
    â”œâ”€â”€ gutenberg_dataset.csv         # Dataset final de parÃ¡grafos + rÃ³tulos
    â”œâ”€â”€ qwen2.5-1.5b-instruct.gguf    # Modelo LLM quantizado
    â”œâ”€â”€ notebook.ipynb                # CÃ³digo exploratÃ³rio
    â””â”€â”€ README.md                     # Este arquivo

## ğŸ§  Modelos Utilizados

### ğŸ”¹ Embeddings

-   **Sentence-BERT -- all-MiniLM-L6-v2**
-   Origem: https://www.sbert.net
-   ReferÃªncia acadÃªmica:\
    **Reimers, N.; Gurevych, I. Sentence-BERT: Sentence Embeddings using
    Siamese BERT-Networks (2019).**

### ğŸ”¹ LLM (InferÃªncia)

-   **Qwen2.5 1.5B Instruct -- GGUF**
-   InferÃªncia via **llama-cpp-python**
-   Roda totalmente offline

### ğŸ”¹ RAG

-   RecuperaÃ§Ã£o baseada em embeddings (k=3 exemplos)
-   Melhora significativa na precisÃ£o em comparaÃ§Ã£o com zero-shot LLM

## ğŸ“Š Resultados e ConclusÃµes

A soluÃ§Ã£o RAG apresentou desempenho superior ao uso do modelo LLM
isolado (zero-shot).\
Isso confirma achados da literatura, especialmente:

-   **Lewis et al.Â (2020)** --- *Retrieval-Augmented Generation*
-   **Reimers & Gurevych (2019)** --- eficÃ¡cia de SBERT para busca
    semÃ¢ntica
-   **Dettmers et al.Â (2023)** --- eficiÃªncia de modelos quantizados

Links recomendados: - https://arxiv.org/abs/2005.11401\
- https://arxiv.org/abs/1908.10084\
- https://arxiv.org/abs/2305.14314

## â–¶ï¸ ExecuÃ§Ã£o

### 1. Instale dependÃªncias

``` bash
pip install sentence-transformers faiss-cpu llama-cpp-python pandas numpy
```

### 2. Baixe o modelo GGUF

``` bash
wget -O qwen2.5-1.5b-instruct.gguf https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf
```

### 3. Gere o dataset

``` python
python build_dataset.py
```

### 4. Rode o classificador

``` python
python classify.py
```

## ğŸ“˜ LicenÃ§a

Este projeto utiliza textos em domÃ­nio pÃºblico e Ã© disponibilizado sob
licenÃ§a MIT.

## âœ¨ Autor

Projeto desenvolvido por Diogo Campanha (2025).
